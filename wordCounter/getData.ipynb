{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\magr3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\magr3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\magr3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\magr3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\magr3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\magr3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 9.04k/9.04k [00:00<00:00, 3.02MB/s]\n",
      "Resolving data files: 100%|██████████| 5534/5534 [00:01<00:00, 5424.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('tiiuae/falcon-refinedweb', split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "WORD1 = re.compile(r'[a-zA-Z]+', re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocces_text(df):\n",
    "    df['content'] = ' '.join([word for word in WORD1.findall(df['content'].lower()) if word not in (stop) ]) #get rid of stop words\n",
    "    #Lemmatizer\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    df['content'] = ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(df['content'])])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = dataset.map(preprocces_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'birch found many place europe photo short trip baden baden cloud background messenger storm kyrill moment trip baden baden ast ray bilingual wordplay ast mean twig german baden baden sound like wordplay actual name rather well know spa town also date back roman time bad german word bath mirror effect turned nice like', 'url': 'http://100parts.wordpress.com/2012/08/04/astray-baden-baden-day-31/', 'timestamp': datetime.datetime(2013, 5, 18, 10, 42), 'dump': 'CC-MAIN-2013-20', 'segment': '1368696382261', 'image_urls': []}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(updated_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progreso:   0%|          | 30.5/20.5k [01:33<17:27:20, 3.07s/MB]\n",
      "c:\\Users\\magr3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:524: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "Progreso: 100%|██████████| 20.5k/20.5k [6:12:59<00:00, 1.09s/MB]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha alcanzado el límite de 20 GB. Deteniendo la iteración.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_size = 0  # Tamaño total acumulado en bytes\n",
    "max_size_gb = 20  # Tamaño máximo en gigabytes\n",
    "\n",
    "# Iniciar la barra de progreso\n",
    "pbar = tqdm(total=max_size_gb*1024, unit='MB', desc='Progreso', unit_scale=True)\n",
    "\n",
    "output_file = 'miniOscar.txt'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for entry in updated_dataset:\n",
    "        text = entry['text']\n",
    "        text_size = len(text.encode('utf-8'))\n",
    "\n",
    "        total_size += text_size\n",
    "        pbar.update(total_size / (1024 * 1024) - pbar.n)  # Actualizar la barra de progreso\n",
    "\n",
    "        if total_size / (1024 * 1024* 1024) >= max_size_gb:\n",
    "            print(\"Se ha alcanzado el límite de 20 GB. Deteniendo la iteración.\")\n",
    "            break\n",
    "        f.write(text + '\\n')\n",
    "\n",
    "pbar.close()  # Cerrar la barra de progreso al finalizar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
